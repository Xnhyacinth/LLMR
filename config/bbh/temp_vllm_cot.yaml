### model
model_name_or_path: meta-llama/Meta-Llama-3-70B-Instruct
# model_name_or_path: meta-llama/Meta-Llama-3-8B
# model_name_or_path: meta-llama/Llama-2-7b-hf
# model_name_or_path: meta-llama/Llama-2-7b-chat-hf
# adapter_name_or_path: saves/llama3-8b/lora/sft

flash_attn: fa2
### method
# finetuning_type: lora

### dataset
task: know/bbh
split: all_task_train_right_answer #all_task_test #all_task_train_right_answer
template: llama3 #fewshot
lang: gen_temp_cot
n_shot: 3

### output
save_dir: saves/llama3-70B-Instruct/temp/bbh/vllm_cot_3shot_llama3_train
# save_dir: saves/llama3-8b/eval/csqa_gen
# save_dir: saves/llama3-8b-Instruct/eval/csqa
# save_dir: saves/llama2-7b-chat/eval/csqa

### eval
batch_size: 8
gen_chat: True
vllm: True

### gen
max_new_tokens: 1024
do_sample: False
# temperature: 0.1
# top_p: 0.75
temperature: 0.8
top_p: 0.9
top_k: 50
repetition_penalty: 1.0
