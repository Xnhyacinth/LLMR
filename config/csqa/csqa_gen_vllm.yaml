### model
model_name_or_path: meta-llama/Meta-Llama-3-70B-Instruct
# model_name_or_path: meta-llama/Meta-Llama-3-8B
# model_name_or_path: meta-llama/Llama-2-7b-hf
# model_name_or_path: meta-llama/Llama-2-7b-chat-hf
# adapter_name_or_path: saves/llama3-8b/lora/sft

flash_attn: fa2
### method
# finetuning_type: lora

### dataset
task: know/commonsenseqa
split: devc
template: fewshot
lang: gen_choice
n_shot: 3

### output
save_dir: saves/llama3-70B-Instruct/eval/csqa_gen_vllm
# save_dir: saves/llama3-8b/eval/csqa_gen
# save_dir: saves/llama3-8b-Instruct/eval/csqa
# save_dir: saves/llama2-7b-chat/eval/csqa

### eval
batch_size: 8
gen_chat: True
vllm: True

### gen
max_new_tokens: 1024
do_sample: False
# temperature: 0.1
# top_p: 0.75
temperature: 0.8
top_p: 0.9
